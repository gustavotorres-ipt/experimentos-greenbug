{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> **Classificação de sons de motores**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/sachinsarkar/urban-sound-classification-usnig-librosa-and-ann/notebook\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa as lb\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential, layers\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carregar um exemplo de arquivo de áudio e mplotar a onda\n",
    "def plot_sound(filename):\n",
    "    librosa_audio_data, librosa_sample_rate = lb.load(filename)\n",
    "    time_x = np.arange(len(librosa_audio_data)) / librosa_sample_rate\n",
    "    plt.plot(time_x, librosa_audio_data)\n",
    "    plt.xlabel(\"Tempo (s)\")\n",
    "\n",
    "filename = './motoserras/07002325.wav'\n",
    "plot_sound(filename)\n",
    "\n",
    "ipd.Audio(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A function that extract and returns numeric features from audio file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corta um arquivo de som em vetores menores de t segundos\n",
    "def split_data(path):\n",
    "    # IMPORTANTE: não foi verificado o conteúdo dos áudios de 5 segundos, provavelmente\n",
    "    # há trechos de sons que devem ser removidos (exemplo: ruídos)\n",
    "    t = 20\n",
    "    data, sample_rate = lb.load(path)\n",
    "\n",
    "    audio_slice_list = []\n",
    "    for i in range(0, len(data), t * sample_rate):\n",
    "        audio_slice_list.append(data[i : t * sample_rate + i])\n",
    "    return audio_slice_list\n",
    "\n",
    "# Extrai features do arquivo de som\n",
    "def feature_extractor(data):\n",
    "    # data, sample_rate = lb.load(path)\n",
    "\n",
    "    data = lb.feature.mfcc(y=data, n_mfcc=128)\n",
    "    data = np.mean(data,axis=1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting Features from Audio files and preparing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading sounds from 2 different folders\n",
    "path_motosserras = \"./motoserras\"\n",
    "path_motores = \"./motores\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = [], []\n",
    "\n",
    "# Carrega todos os sons de motores\n",
    "for filename in os.listdir(path_motores):\n",
    "    path = os.path.join(path_motores, filename)\n",
    "    audio_slice_list = split_data(path)\n",
    "    for audio in audio_slice_list:\n",
    "        x.append(feature_extractor(audio))\n",
    "        y.append(0)\n",
    "\n",
    "# Carrega todos os sons de motoserras\n",
    "for filename in os.listdir(path_motosserras):\n",
    "    path = os.path.join(path_motosserras, filename)\n",
    "    audio_slice_list = split_data(path) \n",
    "    for audio in audio_slice_list:\n",
    "        x.append(feature_extractor(audio))\n",
    "        y.append(1)\n",
    "\n",
    "x = np.array(x)\n",
    "y = np.array(y)\n",
    "x.shape, y.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train, Test and validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrainval, xtest, ytrainval, ytest = train_test_split(x,y,test_size=0.1,stratify=None,random_state=0)\n",
    "xtrain, xvalid, ytrain, yvalid = train_test_split(xtrainval,ytrainval,test_size=0.2, random_state=1)\n",
    "\n",
    "print('\\nNumber of samples for Train set :',xtrain.shape[0])\n",
    "print('Number of samples for Validation set :',xvalid.shape[0])\n",
    "print('Number of samples for Test set :',xtest.shape[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Artificial Neural Network Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential(\n",
    "                        [\n",
    "                            layers.Dense(1000,activation='relu',input_shape=(128,)),\n",
    "                            layers.Dense(750,activation='relu'),\n",
    "                            layers.Dense(500,activation='relu'),\n",
    "                            layers.Dense(250,activation='relu'),\n",
    "                            layers.Dense(100,activation='relu'),\n",
    "                            layers.Dense(50,activation='relu'),\n",
    "                            layers.Dense(1,activation='softmax')\n",
    "                        ]\n",
    "                   )\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training and Compilation of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "training = model.fit(xtrain,ytrain,validation_data=(xvalid,yvalid),epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_hist = pd.DataFrame(training.history)\n",
    "train_hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,8))\n",
    "plt.plot(train_hist[['loss','val_loss']])\n",
    "plt.legend(['loss','val_loss'])\n",
    "plt.title('Loss Per Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(20,8))\n",
    "plt.plot(train_hist[['accuracy','val_accuracy']])\n",
    "plt.legend(['accuracy','val_accuracy'])\n",
    "plt.title('Accuracy Per Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Performance Analysis on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrue = ytest\n",
    "ypred = model.predict(xtest)[:, 0]\n",
    "ypred = np.round(ypred)\n",
    "\n",
    "print('\\n\\nClassification Report : \\n\\n',classification_report(ytrue,ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "plt.title(\"Confusion matrix for testing data\", fontsize = 15)\n",
    "plt.xlabel(\"Predicted class\")\n",
    "plt.ylabel(\"True class\")\n",
    "sns.heatmap(confusion_matrix(ytrue,ypred),annot=True,\n",
    "           xticklabels = ['motor', 'motoserra'], yticklabels=['motor', 'motoserra'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The final Prediction function that takes the audio path and returns the predicted class along with audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(path):\n",
    "    # Lê um arquivo de áudio e separa ele em partes\n",
    "    audio_slice_list = split_data(path)\n",
    "    audio = np.array([feature_extractor(audio_slice_list[0])])\n",
    "    classid = model.predict(audio)[0][0]\n",
    "    classe = 'motosserra' if classid == 1 else 'motor'\n",
    "    print('Classe predita :',classe,'\\n\\n')\n",
    "    return ipd.Audio(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing the Prediction Function on a Audio file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict('./motoserras/07002291.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> **Thank You**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
